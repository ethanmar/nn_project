{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e01d533",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 20:42:16.737302: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/maxwatzky/anaconda3/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "#import necessary libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a342e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the mnist numbers dataset\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e272380e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "ds_train = ds_train.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(128)\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1360d964",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = ds_test.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(128)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c559acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "469/469 [==============================] - 4s 3ms/step - loss: 0.3383 - sparse_categorical_accuracy: 0.8996 - val_loss: 0.1451 - val_sparse_categorical_accuracy: 0.9552\n",
      "Epoch 2/6\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1226 - sparse_categorical_accuracy: 0.9633 - val_loss: 0.1286 - val_sparse_categorical_accuracy: 0.9588\n",
      "Epoch 3/6\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0849 - sparse_categorical_accuracy: 0.9740 - val_loss: 0.0951 - val_sparse_categorical_accuracy: 0.9691\n",
      "Epoch 4/6\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0659 - sparse_categorical_accuracy: 0.9798 - val_loss: 0.0884 - val_sparse_categorical_accuracy: 0.9748\n",
      "Epoch 5/6\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0518 - sparse_categorical_accuracy: 0.9840 - val_loss: 0.0795 - val_sparse_categorical_accuracy: 0.9767\n",
      "Epoch 6/6\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0413 - sparse_categorical_accuracy: 0.9877 - val_loss: 0.0803 - val_sparse_categorical_accuracy: 0.9749\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8380fe88e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#IMPORTANT - WE DESIGN THE NEURAL NETWORK WITH THE FOLLOWING STRUCTURE:\n",
    "  #INPUT LAYER - 128 NEURONS\n",
    "  #HIDDEN LAYER - 64 NEURONS\n",
    "  #HIDDEN LAYER - 28 NEURONS \n",
    "  #OUTPUT LAYER - 10 NEURONS\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(28, activation='relu'),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=6,\n",
    "    validation_data=ds_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4c5435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params will look like:\n",
    "# [ W_flatten→Dense1, b_flatten→Dense1,\n",
    "#   W_Dense1→Dense2,   b_Dense1→Dense2,\n",
    "#   W_Dense2→Dense3,   b_Dense2→Dense3,\n",
    "#   W_Dense3→Dense4,   b_Dense3→Dense4,\n",
    "#   W_Dense4→output,   b_Dense4→output ]\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "params = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "be0d46cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#can't save directly, since each layer has a different size\n",
    "#gotta get creative\n",
    "for i in range(len(params)):\n",
    "    type_string = 'weights' * (i%2 == 0) + 'biases' * (i%2 == 1)\n",
    "    np.save(\"nn_\" + type_string + \"_layer_\" + str(int(i/2)) + \".npy\", params[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
